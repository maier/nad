#!/usr/bin/env node
// -*-Javascript-*-

/* eslint-disable no-process-exit */
/* eslint-disable no-sync */
/* eslint-disable no-bitwise */
/* eslint-disable no-mixed-operators */
/* eslint-disable global-require */
/* eslint-disable no-plusplus */
/* eslint-disable no-param-reassign */
/* eslint-disable guard-for-in */
/* eslit-disable no-nested-ternary */
/* eslint-disable max-params */

'use strict';

//
// Toss executables (scripts too) in /etc/node-agent.d
// Each program should produce lines as follows:
//    <name><whitespace><type>
// or:
//    <name><whitespace><type><whitespace><value>
//
// The first indicates the value is present and null
// the second indicates the value is present and specific
//

// require //////////////////////////////////////////////////////////////

const fs = require('fs');
const http = require('http');
const https = require('https');
const os = require('os');
const path = require('path');
const spawn = require('child_process').spawn;
const url = require('url');

const dutil = require('debug_util');
const chalk = require('chalk');
const pino = require('pino');
const log = pino({
    name: 'nad',
    level: 'info',
    enabled: true
});

const prefixError = chalk.red('ERROR:');
// const prefixWarn = chalk.yellow('WARN:');

const defaultServer = { port: 2609, address: null };

const settings = {
    plugin_dir: '/opt/circonus/etc/node-agent.d', // directory where plugins are located
    is_windows: false, // is running system windows
    is_booted: false, // has bootstrap completed
    drop_uid: 0, // drop privileges to UID, if supported and specified on command line
    cafile: null, // broker ca certificate file (used to set up reverse connection)
    check_bundle_id: null, // id of check bundle to use for reverse connection
    auth_token: null, // circonus api auth token key to use for api calls
    use_reverse_connection: false, // set up a reverse connection to the broker
    target: null, // used by self-configure
    hostname: os.hostname(), // used by self-configure and reverse connection
    broker_id: null, // used by self-configure
    configfile: null, // used by self-configure
    api: { // used by self-configure and reverse connection
        key: null,
        app: 'nad',
        url: 'https://api.circonus.com/v2',
        verbose: false,
        use_apiurl: true, // toggles using the new settings.api.url vs deprecated 'api_options'
        api_options: {
            host: null, // deprecated
            port: null, // deprecated
            path: null, // deprecated
            protocol: null // deprecated
        }
    },
    debug_dir: null, // if set, a dir to write debug logs to
    wipe_debug_dir: false, // if true, wipe debug logs clean before each write
    ssl: {
        verify: false, // use ca certificate for verifications
        listen: [], // server listening address(es)/port(s)
        creds: {} // ssl credentials
    }, // ssl server options
    listen: [] // server listening address(es)/port(s)
};

// isolate windows-specific stuff (if this isn't windows, no reason to load module)
let circwmi = null;

if (process.platform === 'win32') {
    try {
        circwmi = require('circwmi');
    } catch (err) {
        console.error(prefixError, 'unable to load circwmi module', err);
        process.exit(1);
    }
    settings.is_windows = true;
}

log.info('initializing');

// "globals" ///////////////////////////////////////////////////////////

// cache of previous results of running scripts
// this is responded with if a script is still running when
// a request for a new value comes in (which is common with long
// running scripts that periodically output values)
const past_results = {};

// a data structure representing all scripts (aka plugins/native
// plugins.)  Each value in the object contains an object that
// has properties relating to the script.
const scripts = {};

// a collection indicating which scripts that have been run once
// already
const scripts_once = {};

// listener for metrics (see protocol_observer usage in postgres and cassandra plugins)
let push_script = null;

// The script "generation".  A global counter that's incremented
// each time we scan for new scripts on disk.
let generation = 0;

// //////////////////////////////////////////////////////////////////////
// autoconfig with circonus
// //////////////////////////////////////////////////////////////////////
function configure_circonus() {
    let nadapi = null;
    let error = false;

    if (settings.target === null) {
        console.error('--target is required.');
        error = true;
    }

    if (settings.broker_id === null || !(/^\d+$/).test(settings.broker_id)) {
        console.error('--brokerid is required and should be an integer.');
        error = true;
    }

    if (settings.configfile === null) {
        console.error('--configfile is required.');
        error = true;
    }

    if (error) {
        process.exit(1);
    }

    try {
        nadapi = require('nad_circapi');
    } catch (err) {
        log.fatal({ err }, 'failed to load nad_circapi module');
        process.exit(1);
    }

    let api_options = url.parse(settings.api.url);

    if (!settings.api.use_apiurl) {
        api_options = settings.api.old_options;
    }

    nadapi.configure(settings.api.key, settings.target, settings.hostname, settings.broker_id, settings.configfile, api_options);
    process.exit(0);
}


// //////////////////////////////////////////////////////////////////////
// help
// //////////////////////////////////////////////////////////////////////
function help(errMsg) {
    console.log(`${process.argv[1]}\n` +
              `\t-h\t\t\tthis help message\n` +
              `\t-c <pathspec>\t\tplugin/config dir\n` +
              `\t-d\t\t\tturn on debugging messages\n` +
              `\t-p [ip:]<port>\t\tunsecured port\n` +
              `\t-s [ip:]<secureport>\tsecured port\n` +
              `\t-v\t\t\tverify secured traffic\n` +
              `\t-r\t\t\tattempt reverse connection\n` +
              `\t--authtoken\t\tCirconus API auth token to use, if passed will attempt to configure via the Circonus API then exit. [deprecated, use --apikey]\n` +
              `\t--target\t\tTarget Circonus will use to contact this host.\n` +
              `\t--hostname\t\tHostname used in check and graph names (and searching for reverse connection checks), if not passed we will attempt to look it up.\n` +
              `\t--brokerid\t\tID of the Circonus broker to configure the check on.\n` +
              `\t--cid\t\tID of the Circonus check bundle which we will use to find the proper broker for reverse connections.\n` +
              `\t--cafile\t\tpath to CA certificate file to use for the broker during reverse connections.\n` +
              `\t--configfile\t\tName of the file in the config directory to use for Circonus configuration.\n` +
              `\t--debugdir\t\tCreate debug files for each script and write them to this directory.\n` +
              `\t--wipedebugdir\t\tWipe debug files clean before each write.\n` +
              `\t--apikey\t\tCirconus API auth token key to use, (used by self-config or reverse connection) alternate to --authtoken.\n` +
              `\t--apiapp\t\tCirconus API auth token app to use, (used by self-config or reverse connection). default: 'nad'\n` +
              `\t--apiurl\t\tCirconus API URL to use, (used by self-config or reverse connection). alternate to --api(host,port,path,protocol) default: https://api.circonus.com/v2\n` +
              `\t--apihost\t\tOverride the host for the Circonus API server (default: api.circonus.com) [deprecated, use --apiurl]\n` +
              `\t--apiport\t\tOverride the port for the Circonus API server (default: 443) [deprecated, use --apiurl]\n` +
              `\t--apipath\t\tOverride the path for the Circonus API server (default: /v2) [deprecated, use --apiurl]\n` +
              `\t--apiprotocol\t\tOverride the protocol for the Circonus API server (default: https) [deprecated, use --apiurl]\n` +
              `\t--apiverbose\t\tOutput API traffic to STDERR\n` +
              `\t-i\t\t\toffline inventory\n`
            );
    if (errMsg) {
        console.error(prefixError, errMsg);
        process.exit(-1);
    }
}

// //////////////////////////////////////////////////////////////////////
// setuid
// //////////////////////////////////////////////////////////////////////

function post_boot() {
    settings.is_booted = true;

    if (settings.drop_uid > 0 && process.setuid) {
        log.info({ uid: settings.drop_uid }, 'dropping privileges');
        process.setuid(settings.drop_uid);
    }

    if (settings.use_reverse_connection) {
        log.info('setting up reverse connection');
        let reverse = null;

        try {
            reverse = require('reverse');
        } catch (err) {
            log.fatal({ err }, 'unable to set up reverse connection');
            process.exit(1);
        }

        let api_options = url.parse(settings.api.url);

        if (!settings.api.use_apiurl) {
            api_options = settings.api.old_options;
        }

        const options = {
            cafile: settings.cafile,
            hostname: settings.hostname,
            auth_token: settings.api.key,
            api_options,
            check_bundle_id: settings.check_bundle_id,
            server_port: settings.listen[0].port
        };

        reverse(options, log);
    }

    log.debug('bootstrap complete');
}

// //////////////////////////////////////////////////////////////////////
// executing scripts
// //////////////////////////////////////////////////////////////////////

// merge_types takes two char type descriptors and returns the
// smallest type that could non-erroneously represent them
function merge_types(typeA, typeB) {
    if (typeA === typeB) {
        return typeA;
    }
    // There are four source cases where we can upgrade to int64_t
    if (typeA === 'i' && (typeB === 'I' || typeB === 'l')) {
        return 'l';
    }
    if (typeA === 'I' && (typeB === 'i' || typeB === 'l')) {
        return 'l';
    }
    if (typeA === 'l' && (typeB === 'i' || typeB === 'I')) {
        return 'l';
    }
    if (typeA === 'L' && typeB === 'I') {
        return 'l';
    }
    // otherwise we have to just jump to a double
    return 'n';
}

// runs a single script / native plugin and then fire a callback
//   plugin is the object for the script that's stored in 'scripts'
//   cb is what we call back when done
//   req is the request object (passed to native plugins)
//   args is any arguments that came from the per script config file
//   instance is the specific instance of plugin to run
function run_script(plugin, cb, req, args, instance) {

    log.info({ name: instance }, 'running plugin');

    // (we don't re-run scripts that are already running)
    plugin.running = true;
    plugin.last_start = Date.now();

    // per process data
    const proc_data = {
        // incomplete line of data buffered between callbacks.
        data: '',

        // complete lines of data that have yet to
        // be handled (parsed for JSON and/or tab
        // file format.)  We only parse the output
        // when we reach the end of the output or a
        // blank line
        lines: [],

        options: {}
    };

    // if this is a native plugin then all we need to do
    // is call the run method on the instance stored within d.obj
    // and we're done, so return
    if (plugin.native_plugin) {
        plugin.obj.run(plugin,
            (_plugin, _metrics, _instance) => {
                past_results[_instance] = _metrics;
                cb(_plugin, _metrics, _instance);
            }, req, args, instance);
        return;
    }

    // execute the command
    const cmd = spawn(plugin.command, args);

    function kill_func() {
        cmd.stdin.destroy();
        cmd.stdout.destroy();
        cmd.stderr.destroy();
        cmd.kill();
    }

    // create a function that can handle output from the process we
    // just created.  This will be called from the code below whenever
    // we reach the end of the process output, or a blank line is found in
    // the output
    function handle_output(pluginDef, pluginCB, pluginInstance) {
        if (proc_data.timeout) {
            clearTimeout(proc_data.timeout);
        }
        pluginDef.last_finish = Date.now();
        let results = {};

        // if someone has specified a debug dir, then log out
        // the record we collected to that
        if (settings.debug_dir !== null) {
            dutil.write_debug_output(pluginDef.name, proc_data.lines, settings.debug_dir, settings.wipe_debug_dir);
        }

        // attempt to process the lines as json...
        try {
            results = JSON.parse(proc_data.lines.join(' '));
        } catch (err) {
            // ... but if that doesn't work, try the tab delim format
            for (const line of proc_data.lines) {
                const parts = (/^\s*(metric\s+)?(\S+)\s+(string|int|float|[iIlLns])(\s*)(.*)$/).exec(line);

                if (parts) {
                    const name = parts[2];
                    let type = parts[3];
                    const space = parts[4];
                    const val = parts[5];
                    const isnull = space.length === 0 || val === '[[null]]';

                    type = type.length > 1 ? type === 'float' ? 'n' : type.substr(0, 1) : type; // eslint-disable-line no-nested-ternary

                    if (type !== 's' &&  // this is numeric
                        {}.hasOwnProperty.call(results, name) && results[name]._type !== 's' && // preexists as numeric
                        {}.hasOwnProperty.call(results[name], '_value')) {
                        if (!Array.isArray(results[name]._value)) { // upgrade to array
                            results[name]._value = [ results[name]._value ];
                        }
                        // we're in a position to append the result instead of set it.
                        results[name]._value.push(isnull ? null : val);
                        // we also might need to "upgrade the type"
                        results[name]._type = merge_types(type, results[name]._type);
                    } else {
                        results[name] = {
                            _type: type,
                            _value: isnull ? null : val
                        };
                    }
                }
            }
        }

        // remember the past results
        past_results[pluginInstance] = results;

        // execute the callback
        pluginCB(pluginDef, results, pluginInstance);
    }

    // hook up the process so whenever we complete reading data
    // from the process we call "handle_output" and process
    // any remaining data (i.e. any partial line still in
    // our between callback buffer)
    cmd.stdout.on('end', () => {
        handle_output(plugin, cb, instance);
    });

    // hook up an anonymous function to the process to be called
    // whenever we get output.  The way this works is basically
    // there's two buffers used between calls: proc_data.lines
    // representing all lines of data we haven't processed yet
    // and proc_data.data representing an incomplete line
    cmd.stdout.on('data', (buff) => {
        let offset = null;

        // append output we collected to the incomplete line buffer
        // we're using to cache data between "data" callbacks
        proc_data.data += buff;

        // extract each complete line of data that's in the
        // between callback buffer and leave only the remaining
        // incomplete line in that buffer
        while ((offset = proc_data.data.indexOf('\n')) >= 0) {
            // extract a single line of data from the start of the string
            // pay attention to windows line endings if there are any!
            const line = proc_data.data.substring(0,
                     offset > 0 &&
                      proc_data.data.charAt(offset - 1) === '\r' ?
                         offset - 1 : offset);

            // is this a "comment" that contains meta information in a JSON blob?
            if (line.charAt(0) === '#') {
                try {
                    proc_data.options = JSON.parse(line.substring(1));
                } catch (err) {
                    log.error({ err }, 'Error parsing proc otions');
                }

                // set a timeout to stop this run if requested in meta block
                if (proc_data.options.timeout) {
                    proc_data.timeout = setTimeout(kill_func,
                                         proc_data.options.timeout * 1000);
                }
            } else {
                // if this line has data in it, simply shuffle it into
                // list of lines that will need to be processed
                if (line.length) { // eslint-disable-line no-lonely-if
                    proc_data.lines.push(line);
                } else {
                    // however if the line doesn't have data in it it's a blank
                    // line, meaning we should attempt to process everything that
                    // we've collected so far up until this point
                    handle_output(plugin, cb, instance);
                }
            }

            // discard this line from the buffer we're using between
            // "data" callbacks and move onto processing the next one
            // if there is (or keep it for next callback if there isn't)
            proc_data.data = proc_data.data.substring(offset + 1);
        }
    });

    // when the command is done, mark it as no longer running.
    cmd.on('exit', (code, signal) => { // eslint-disable-line no-unused-vars
        plugin.running = false;
    });

  // if there's any error running the command, log it and remove
  // it from the list of scripts we're running
    cmd.on('error', (err) => {
        log.error({ err, cmd: plugin.command }, `Error on command, removing from scripts`);
        proc_data.data = '';
        plugin.running = false;
        delete scripts[plugin.name];
    });
}

// per script config
function get_config(req, plugin, cb) {
    // short-circuit if the plugin doesn't have a config
    if (!plugin.config) {
        run_script(plugin, cb, req, [], plugin.name);
        return;
    }

    log.debug({ name: plugin.name, config: plugin.config }, 'applying plugin config');

    const instance_count = Object.keys(plugin.config).length;

    // Add the number of time we will run this script to our
    // total run_count so we don't finish early.
    if (req && instance_count > 1) {
        req.nad_run_count += instance_count - 1;
    }

    for (const instance in plugin.config) {
        run_script(plugin, cb, req, plugin.config[instance], `${plugin.name}\`${instance}`);
    }
}

function init_script(plugin, req, cb) {
    log.debug({ name: plugin.name }, 'initializing plugin');
    if (plugin.running) {
        log.debug({ name: plugin.name }, 'plugin already running, returning previous result');
        cb(plugin, past_results[plugin.name], plugin.name);
        return;
    }
    get_config(req, plugin, cb);
}


// //////////////////////////////////////////////////////////////////////
// process commmand line arguments
// //////////////////////////////////////////////////////////////////////

for (let i = 2; i < process.argv.length; i++) {
    switch (process.argv[i]) {
        case '-d': {
            log.level = 'debug';
            log.debug('debug logging enabled');
            break;
        }

        case '-h': {
            help();
            process.exit(0);
            break;
        }

        // set the config [meaning 'plugin'] dir
        case '-c': {
            settings.plugin_dir = fs.realpathSync(process.argv[++i]);
            break;
        }

        // offline inventory
        case '-i': {
            // if we're just indexing, do that then quit
            let index = null;

            try {
                index = require('indexer');
            } catch (err) {
                const msg = 'unable to load index module';

                console.error(prefixError, msg, err);
                log.fatal({ err }, msg);
                process.exit(1);
            }

            index(settings.plugin_dir);
            process.exit(0);
            break;
        }

        // switch to this uid after starting
        // (only if node supports it on the host os)
        case '-u': {
            const uid = parseInt(process.argv[++i], 10);

            if (uid <= 0) {
                log.warn({ uid }, 'invalid drop uid specified');
                break;
            }

            if (!process.setuid) {
                log.warn({ platform: process.platform }, 'dropping permissions not supported');
                break;
            }

            settings.drop_uid = uid;
            break;
        }

        // specify one or more ports (and, optionally, IP) to listen for
        // http requests on. either in the form "8080" or "127.0.0.1:8080"
        case '-p': {
            const portSpec = process.argv[++i].split(/:/);

            if (portSpec.length === 1) {
                portSpec.unshift(null);
            }
            if (portSpec.length !== 2) {
                help('-p [ip:]port');
            }
            settings.listen.push({ port: parseInt(portSpec[1], 10), address: portSpec[0] });
            break;
        }

        // specify one or more ports (and, optionally, IP) to listen for
        // https requests on either in the form "4443" or "127.0.0.1:4443"
        case '-s': {
            const sslPortSpec = process.argv[++i].split(/:/);

            if (sslPortSpec.length === 1) {
                sslPortSpec.unshift(null);
            }
            if (sslPortSpec.length !== 2) {
                help('-s [ip:]port');
            }
            settings.ssl.listen.push({ port: parseInt(sslPortSpec[1], 10), address: sslPortSpec[0] });
            break;
        }

        // should we verify using a certificate authority the SSL certificate presented?
        // applies to listening SSL ports
        case '-v': {
            settings.ssl.verify = true;
            break;
        }

        // options for reverse connections

        case '-r': {
            settings.use_reverse_connection = true;
            break;
        }

        case '--cid': {
            settings.check_bundle_id = process.argv[++i];
            break;
        }

        case '--cafile': {
            settings.cafile = process.argv[++i];
            break;
        }

        // options for autoconfig with circonus api [self-configure]

        case '--target': {
            settings.target = process.argv[++i];
            break;
        }

        case '--hostname': {
            // NOTE: used by both self-configure and reverse connection
            settings.hostname = process.argv[++i];
            break;
        }

        case '--brokerid': {
            settings.broker_id = process.argv[++i];
            break;
        }

        case '--configfile': {
            settings.configfile = fs.realpathSync(process.argv[++i]);
            break;
        }

        // api options

        case '--apikey':
        case '--authtoken': {
            const api_key = process.argv[++i];

            if (!(/^[0-9a-fA-F]{4}(?:[0-9a-fA-F]{4}-){4}[0-9a-fA-F]{12}$/).test(api_key)) {
                console.error(prefixError, '(--apikey|--authtoken) should be a UUID.');
                process.exit(1);
            }
            settings.api.key = api_key;
            break;
        }

        case '--apiapp': {
            // override default circonus api token app 'nad'
            settings.api.app = process.argv[++i];
            break;
        }

        case '--apiurl': {
            // NOTE: using this will override all other --api(host,port,path,protocol) options set
            settings.api.url = process.argv[++i];
            break;
        }

        case '--apihost': {
            // TODO: deprecate
            log.warn('--apihost is deprecated use --apiurl');
            settings.api.use_apiurl = false;
            settings.api.old_options.host = process.argv[++i];
            break;
        }

        case '--apiport': {
            // TODO: deprecate
            log.warn('--apiport is deprecated use --apiurl');
            settings.api.use_apiurl = false;
            settings.api.old_options.port = process.argv[++i];
            break;
        }

        case '--apipath': {
            // TODO: deprecate
            log.warn('--apipath is deprecated use --apiurl');
            settings.api.use_apiurl = false;
            settings.api.old_options.path = process.argv[++i];
            break;
        }

        case '--apiprotocol': {
            // TODO: deprecate
            log.warn('--apiprotocol is deprecated use --apiurl');
            settings.api.use_apiurl = false;
            settings.api.old_options.protocol = process.argv[++i];
            break;
        }

        case '--apiverbose': {
            settings.api.verbose = true;
            break;
        }

        // debugging of plugin metrics

        case '--debugdir': {
            settings.debug_dir = fs.realpathSync(process.argv[++i]);
            break;
        }

        case '--wipedebugdir': {
            settings.wipe_debug_dir = true;
            ++i;
            break;
        }


        // unknown option, just display the helptext

        default: {
            help(`unknown argument: ${process.argv[i]}`);
        }
    }
}

// there are only two purposes for specifying an api auth token key
// 1. reverse connections
// 2. an attempt to self-configure
// if an auth token is supplied but there is no '-r'everse option specified
// it is implied to be #2. so, attempt a self-configuration.
if (settings.auth_token !== null) {
    if (!settings.use_reverse_connection) {
        configure_circonus();
        process.exit(0);
    }
}

// setup ports / ssl
if (settings.listen.length === 0) {
    settings.listen.push(defaultServer);
}

if (settings.listen.length === 0 && settings.ssl.listen.length === 0) {
    help('must specify at least one of -p and -s');
}

if (settings.ssl.listen.length > 0) {
    try {
    // Setup creds
        settings.ssl.creds.key = fs.readFileSync(path.join(settings.plugin_dir, 'na.key')).toString();
        settings.ssl.creds.cert = fs.readFileSync(path.join(settings.plugin_dir, 'na.crt')).toString();
        if (settings.ssl.verify) {
            settings.ssl.creds.ca = fs.readFileSync(path.join(settings.plugin_dir, 'na.ca')).toString();
        }
    } catch (err) {
        log.error('Make sure:');
        log.error(`\tyour key is available: ${path.join(settings.plugin_dir, 'na.key')}`);
        log.error(`\tyour cert is available: ${path.join(settings.plugin_dir, 'na.crt')}`);
        if (settings.ssl.verify) {
            log.error(`\tyour ca is available: ${path.join(settings.plugin_dir, 'na.ca')}`);
        }
        log.error(`\n${err}`);
        process.exit(-1);
    }
}

// //////////////////////////////////////////////////////////////////////
// scanning for plugins (both native and non-native)
// //////////////////////////////////////////////////////////////////////

// a handy function returning a callback that will
// determine if a file has changed on not.
// Used by rescan_modules
function onchange(cb) {
    return (curr, prev) => {
        if (curr.ino !== prev.ino ||
            curr.size !== prev.size ||
            curr.mtime.valueOf() !== prev.mtime.valueOf() ||
            curr.mode !== prev.mode) {
            cb();
            return;
        }
    };
}

// run each script in scripts that hasn't had an initial
// run yet (and then remember it _has_ had an initial run)
function initial_pass() {
    log.debug('initial pass');

    for (const which in scripts) {
        if (!(which in scripts_once)) {
            init_script(scripts[which], null, () => {});
            scripts_once[which] = true;
        }
    }

    if (!settings.is_booted) {
        post_boot();
    }
}


// look on disk for updates to the config dir where
// we keep all our modules (aka plugins / aka scripts)
function rescan_modules() {

    log.debug({ dir: settings.plugin_dir }, 'scanning for plugins');

    // this keeps track of how many filesystem stats we have
    // "in progress" and are still waiting for callbacks on
    let progress = 0;

    // generation is the global number of times rescan_modules has been
    // called.  Each time we rescan our modules we increase it
    // by one.
    generation++;

    // this is a handy private function that goes through
    // all the scripts in our scripts object and removes
    // any that haven't had their generation number updated
    // to our current generation number once we've done
    // scanning
    function sweep() {
        // don't do this while we're still waiting for
        // stat requests that are in progress
        if (progress !== 0) {
            return;
        }

        log.debug('sweep');

        // clear out any out of date scripts
        for (const script in scripts) {
            if (scripts[script].generation < generation) {
                log.debug({ name: script.name }, 'removing expired plugin');
                fs.unwatchFile(scripts[script].command);
                delete scripts[script];
                delete scripts_once[script];
            }
        }

        // run the initial run for any new scripts
        initial_pass();
    }

    function genStatCallback(name, file) {
        return (err, sb) => {
            if (err !== null) {
                log.warn({ err, file }, 'unable to stat file');
                return;
            }

            if (!sb) {
                log.warn({ sb, file }, 'bad stat object for file');
                return;
            }

            if (!sb.isFile()) {
                log.debug({ dir_entry: name }, 'ignoring, not a file');
                return;
            }

            const is_native = (/\.js$/).test(file);
            const is_executable = sb.mode & parseInt('0111', 8);

            if (!(settings.is_windows || is_native || is_executable)) {
                log.debug({ dir_entry: name }, 'ignoring, not a valid file');
                return;
            }

            // if the file is something we should deal with
            // (is a file, and either ends in .js or is executable, or we're running on
            // windows where everything is considered executable)

            log.debug({ name }, 'found plugin');
                // watch the file for future updates.  i.e. if the file changes
                // again later then retrigger this rescan_modules routine
            fs.watchFile(file, onchange(rescan_modules));
                // setup the details in the scripts object for this file
            if (!(name in scripts)) {
                scripts[name] = {};
            }
            const def = scripts[name];

            def.name = name;
            def.generation = generation;
            def.command = file;
            def.native_plugin = is_native;
            def.running = false;
            def.sb = sb;
            def.config = null;

            const cfgFile = path.join(settings.plugin_dir, `${name}.json`);

            if (fs.existsSync(cfgFile)) {
                try {
                    def.config = require(cfgFile);
                } catch (cfgErr) {
                    if (cfgErr.code !== 'MODULE_NOT_FOUND') {
                        const msg = 'error loading config file';

                        console.error(prefixError, msg, cfgErr);
                        log.fatal({ err: cfgErr, file: cfgFile }, msg);
                        process.exit(1);
                    }
                }
            }

            // if this is a "native plugin", i.e. a plugin written in
            // javascript with a ".js" extension then simply load
            // the code directly into node and then create
            // an instance 'obj' to shove in the scripts data structure
            if (def.native_plugin) {
                let Plugin = null;

                try {
                    Plugin = require(def.command);
                } catch (perr) {
                    const msg = 'unable to load native plugin';

                    console.error(prefixError, msg, def.command, perr);
                    log.fatal({ err: perr, file: def.command }, msg);
                }

                def.obj = new Plugin();
            }

                // Only remove items on initial scan
            if (generation === 1) {
                dutil.init_debug(name, settings.debug_dir);
            }

            progress--;
            sweep();
        };
    }

    // look in the config directory
    fs.readdir(settings.plugin_dir, (err, files) => {

        // bomb out if there's any error (we don't do any fancy
        // error handling or attempt any form of recovery)
        if (err) {
            const msg = 'unable to read config directory';

            console.error(prefixError, msg, err);
            log.fatal({ err, dir: settings.plugin_dir }, msg);
            process.exit(-1);
        }

        // inc our reference count
        progress++;

        // for each file in the config directory
        for (const file of files) {
            const fileParts = path.parse(path.join(settings.plugin_dir, file));

            // if file is not in form name.extension, ignore
            if (fileParts.name === '' || fileParts.ext === '') {
                log.debug({ dir_entry: file }, 'ignoring, invalid name');
                continue;
            }

            // if a configuration file, ignore
            if (fileParts.ext === '.conf' || fileParts.ext === '.json') {
                log.debug({ dir_entry: file }, 'ignoring, config file');
                continue;
            }

            const filename = path.join(fileParts.dir, fileParts.base);

            // stop watching the file for updates
            fs.unwatchFile(filename);

            // note we need to wait for stat callback to be
            // called before we're done
            progress++;

            // stat the file
            fs.stat(filename, genStatCallback(fileParts.name, filename));
        }
        progress--;
        sweep();
    });
}


// this is called from the "webserver" part, it's job is:
//   1. Run all scripts
//   2. Put the output as JSON into the passed result
function run_scripts(req, res, which) {
    log.debug('run_scripts call');
    // this is a per-request counter that lets us know
    // when all scripts have returned and it's safe to
    // stringify out the output.
    req.nad_run_count = 0;

    // this is the data structure we're going to populate
    // with the results and eventually stringify out as JSON
    const set = {};

    // called when complete to actually send 'set' out as JSON
    function send_complete() {
        if (req.nad_run_count !== 0) {
            return;
        }
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.write(JSON.stringify(set));
        res.end();
    }

    // if they asked for a particular script and it didn't exist
    // then just send a 404
    if (which && !(which in scripts)) {
        res.writeHead(404);
        res.end();
    } else {
        // otherwise we're going to populate "set" and send it back
        // either just with the script they asked for in which or,
        // if nothing was passed in which, with every script

        // first work out how many scripts we're going to wait to run
        for (const file in scripts) {
            if (which && file !== which) {
                continue;
            }
            req.nad_run_count++;
        }

        // add one for the push_script
        if (!which) {
            req.nad_run_count++;
        }

        // call init script for each script (which will run it) and
        // then when it returns in the callback populate set with
        // the result.  Keep track of how many scripts are left to run
        for (const file in scripts) {
            if (which && file !== which) {
                continue;
            }
            init_script(scripts[file], req, (def, results, name) => {
                req.nad_run_count--;
                set[name] = results;
                send_complete();  // only sends if all scripts are done
            });
        }

        // call the global push receiver script to spit out anything collected
        // over http
        if (!which) {
            init_script(push_script, req, (def, results, name) => {
                req.nad_run_count--;
                if (results !== null) {
                    for (const group in results) {
                        set[group] = results[group];
                    }
                    if (settings.debug_dir !== null) {
                        dutil.write_debug_output(name, [ 'Returning push_receiver data', JSON.stringify(results) ], settings.debug_dir, settings.wipe_debug_dir);
                    }
                }
                send_complete();  // only sends if all scripts are done
            });
        }

        send_complete(); // only sends if there were no scripts to run
    }
}

// //////////////////////////////////////////////////////////////////////
// process web requests
// //////////////////////////////////////////////////////////////////////

// this is the callback that's called whenever something connects
// to our webserver (either any of the http or the https servers)

function handler(req, res) {
    const bodyChunks = [];

    req.addListener('data', (chunk) => {
        bodyChunks.push(chunk);
    });

  // wait for the request to be completely formed (by registering
  // a callback on the 'end' event) and then send back the result
    req.addListener('end', () => {
        let matches = null;
        const urlPath = url.parse(req.url).pathname;
        const body = Buffer.concat(bodyChunks).toString();

        // request for meta-info about the scripts
        if (/^\/inventory/.test(urlPath)) {
            res.writeHead(200, { 'Content-Type': 'application/json' });
            res.write(JSON.stringify(scripts));
            res.end();
            return;
        }

        // request to run all scripts and return results
        if (/^\/(?:run)?$/.test(urlPath)) {
            run_scripts(req, res);
            return;
        }

        // request to run just one script and return results
        matches = (/^\/run\/(.+)$/).exec(path);
        if (matches) {
            run_scripts(req, res, matches[1]);
            return;
        }

        // wmi
        if (settings.is_windows) {
            if ((/^\/wmi\/get-categories$/).test(path)) {
                circwmi.get_categories(res);
                return;
            }
            matches = (/^\/wmi\/(.+)$/).exec(path);
            if (matches) {
                circwmi.get_counters_for_category(res, matches[1], settings.debug_dir, settings.wipe_debug_dir);
                return;
            }
        }

        // plugin
        matches = (/^\/write\/(.+)$/).exec(path);
        if (matches) {
            if (req.method !== 'PUT' && req.method !== 'POST') {
                res.writeHead(405, 'Method Not Allowed', { Allow : 'PUT, POST' });
                res.end();
                return;
            }
            if (settings.debug_dir !== null) {
                dutil.write_debug_output(matches[1], [ 'Receiving push_receiver data', body ], settings.debug_dir, settings.wipe_debug_dir);
            }
            push_script.obj.some_data(matches[1], body);
            res.writeHead(200, 'OK', { 'Content-Type': 'text/plan' });
            res.end();
            return;
        }
        res.writeHead(404);
        res.end();
    });

    // if we don't have a data listener the stream starts paused in node 10+
    req.addListener('data', () => {});
}

// initialize: look for modules, and register a handler to
// rescan the modules every time the directory with the modules
// in it changes
fs.watchFile(settings.plugin_dir, onchange(rescan_modules));
rescan_modules();

// add our specialized push script that handles incoming POST data from any local data spurters
try {
    log.debug('loading push receiver');

    let PushReceiver = null;

    try {
        PushReceiver = require('push_receiver');
    } catch (err) {
        const msg = 'failed to load push_recever module';

        console.error(prefixError, msg, err);
        log.fatal({ err }, msg);
        process.exit(1);
    }

    push_script = {};
    push_script.name = 'dumpster';
    push_script.native_plugin = true;
    push_script.running = false;
    push_script.obj = new PushReceiver();

    log.info('push receiver server started');

} catch (err) {
    const msg = 'unable to initialize push receiver';

    console.log(prefixError, msg, err);
    log.fatal({ err }, msg);
    process.exit(1);
}

// //////////////////////////////////////////////////////////////////////
// start webservers
// //////////////////////////////////////////////////////////////////////

for (const server of settings.listen) {
    log.debug({ server }, 'starting server');

    try {
        http.createServer(handler).listen(server.port, server.address);
        log.info({ server }, 'server started');
    } catch (err) {
        const msg = 'failed to start server';

        console.error(prefixError, msg, server, err);
        log.fatal({ server, err }, msg);
        process.exit(-1);
    }
}


for (const server of settings.ssl.listen) {
    log.debug({ server }, 'starting SSL server');

    try {
        https.createServer(settings.ssl.creds, handler).listen(server.port, server.address);
        log.info({ server }, 'server started');
    } catch (err) {
        const msg = 'failed to start SSL server';

        console.error(prefixError, msg, server, err);
        log.fatal({ server, err }, msg);
        process.exit(-1);
    }
}

// //////////////////////////////////////////////////////////////////////
// done
// //////////////////////////////////////////////////////////////////////

// initial setup is all done now
// at this point if we've started servers etc the process will keep
// running even though we "fall off the end" of the code here
